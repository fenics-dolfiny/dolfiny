stages:
   - lint
   - image
   - test
   - demo
   - book
   - release

variables:
   CONTAINER_COMMIT_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG

workflow:
   auto_cancel:
      on_new_commit: interruptible
   rules:
      - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS
        when: never
      - if: $CI_COMMIT_BRANCH

# jobs
default:
   interruptible: true
   tags: 
      - zed

ruff:
   stage: lint
   image: dolfinx/dev-env:current
   script:
      - pip install ruff
      - ruff format --check
      - ruff check .

mypy:
   stage: lint
   image: dolfinx/dolfinx:nightly
   script:
      - pip install .[typing]
      - mypy -p dolfiny
      - mypy test/ demo/ --explicit-package-bases

typos:
   stage: lint
   image: python:3.13-slim
   script:
      - pip install typos
      - typos

image build:
   stage: image
   image: docker:git
   services:
      - name: docker:dind
        command: ["--mtu=1450"]
   tags:
      - zed
   before_script:
      - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
   script:
      - echo CONTAINER_COMMIT_IMAGE = "$CONTAINER_COMMIT_IMAGE"
      - docker pull $CONTAINER_COMMIT_IMAGE-$ARCH || true
      - docker build
               --cache-from $CONTAINER_COMMIT_IMAGE-$ARCH
               --build-arg BUILDKIT_INLINE_CACHE=1
               --pull
               --push
               --tag $CONTAINER_COMMIT_IMAGE-$ARCH
               --file docker/Dockerfile
               .
   parallel:
      matrix:
         - ARCH: [amd64, arm64]

image release:
   stage: release
   image: docker:git
   services:
      - name: docker:dind
        command: ["--mtu=1450"]
   before_script:
      - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY
      - docker login -u $DOCKERHUB_USER -p $DOCKERHUB_PASSWORD
   script:
      - echo "Gitlab registry -- create multiarch manifest"
      - docker pull $CONTAINER_COMMIT_IMAGE-amd64
      - docker pull $CONTAINER_COMMIT_IMAGE-arm64
      - docker buildx imagetools create -t $CONTAINER_COMMIT_IMAGE $(printf "$CONTAINER_COMMIT_IMAGE-%s " amd64) # FIXME: arm64)
      - echo "DockerHub registry -- create multiarch manifest"
      - docker tag $CONTAINER_COMMIT_IMAGE-amd64 $DOCKERHUB_COMMIT_IMAGE-amd64
      - docker tag $CONTAINER_COMMIT_IMAGE-arm64 $DOCKERHUB_COMMIT_IMAGE-arm64
      - docker push $DOCKERHUB_COMMIT_IMAGE-amd64
      - docker push $DOCKERHUB_COMMIT_IMAGE-arm64
      - docker buildx imagetools create -t $DOCKERHUB_COMMIT_IMAGE $(printf "$DOCKERHUB_COMMIT_IMAGE-%s " amd64) # FIXME: arm64)
   rules:
      - if: $CI_COMMIT_TAG
        variables:
           DOCKERHUB_COMMIT_IMAGE: dolfiny/dolfiny:$CI_COMMIT_TAG
      - if: ($CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $CI_PIPELINE_SOURCE == "schedule")
        variables:
           DOCKERHUB_COMMIT_IMAGE: dolfiny/dolfiny:nightly
      - if: ($CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH)
        variables:
           DOCKERHUB_COMMIT_IMAGE: dolfiny/dolfiny:latest

wheel release:
   stage: release
   image: dolfinx/dev-env:current
   variables:
      PYPI_PACKAGES_URL: ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/pypi
   script:
      - pip install build twine
      - python -m build
      - python -m twine upload -u gitlab-ci-token -p ${CI_JOB_TOKEN} --repository-url ${PYPI_PACKAGES_URL} dist/*
      - python -m twine upload -u ${PYPI_USER} -p ${PYPI_PASSWORD} dist/*
   only:
      - tags

.install_template:
   image: $CONTAINER_COMMIT_IMAGE-$ARCH
   tags:
      - zed
      - saas-linux-large-$ARCH
   script:
      - echo "Apply optional runtime hot-fixes here."
   parallel:
      matrix:
         - ARCH: [amd64] # FIXME: arm64

.test_template:
   stage: test
   extends: .install_template
   before_script:
      - export COVERAGE_PROCESS_START=pyproject.toml
      - pip install coverage_enable_subprocess
   after_script:
      - coverage combine -a
      - coverage report -m
      - coverage xml
   coverage: '/[Tt][Oo][Tt][Aa][Ll].*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'
   artifacts:
      name: "$CI_PROJECT_NAME-$CI_JOB_NAME-$CI_COMMIT_REF_SLUG-$ARCH-artifacts"
      paths:
         - "report.xml"
         - "coverage.xml"
         - "test_*.json"
         - "test_*.pdf"
      reports:
         junit: report.xml
         coverage_report:
            coverage_format: cobertura
            path: coverage.xml
      expire_in: 2 hours

test/unit/serial:
   extends: .test_template
   script:
      - coverage run -m pytest -vsx test/unit # FIXME: -n $(nproc)

test/unit/parallel:
   extends: .test_template
   script:
      - mpirun -n $(nproc) coverage run -m pytest -vsx test/unit

test/convergence:
   extends: .test_template
   script:
      - coverage run -m pytest -n $(nproc) -m 'convergence' -vsx test/convergence
      - coverage run -m pytest -n $(nproc) -m 'postprocess' -vsx test/convergence
   rules:
      - if: ($DOLFINY_TEST_CONVERGENCE == "yes")
      - exists:
         - "test/convergence/*.py"
        when: manual
        allow_failure: true

.demo_template:
   stage: demo
   extends: .install_template
   rules:
      - if: ($CI_PIPELINE_SOURCE == "merge_request_event")
      - if: ($CI_PIPELINE_SOURCE == "schedule")
      - if: ($CI_PIPELINE_SOURCE == "push")
        changes:
         - "demo/*/*.py"
      - exists: 
         - "demo/*/*.py"
        when: manual
        allow_failure: true
   artifacts:
      name: "$CI_PROJECT_NAME-$CI_JOB_NAME-$CI_COMMIT_REF_SLUG-$ARCH-artifacts"
      paths:
         - "demo/*/*"
      expire_in: 2 hours
   variables:
      PARALLEL: True
   script:
      - cd demo/$DIRECTORY
      - |
         # Convert SCRIPTS to array to handle complete command lines with arguments
         # instead of splitting on each word (which breaks "script.py --arg value")
         eval "SCRIPT_ARRAY=($SCRIPTS)"
         for script in "${SCRIPT_ARRAY[@]}"; do
            mpirun -n 1 python $script
            if $PARALLEL; then
               mpirun -n $(nproc) python $script
            fi
         done

bingham:
   extends: .demo_template
   variables:
      DIRECTORY: bingham
      SCRIPTS: >
         bingham_block.py
         bingham_lm_block.py

beam:
   extends: .demo_template
   variables:
      DIRECTORY: beam
      SCRIPTS: >
         beam_curved_finitestrain_bstar.py
         beam_curved_finitestrain_bzero.py

vsolid:
   extends: .demo_template
   variables:
      DIRECTORY: vsolid
      SCRIPTS: >
         duffing.py
         solid_disp_tda.py
         solid_dispstress_tda.py
         solid_velostress_tda.py

plasticity:
   extends: .demo_template
   variables:
      DIRECTORY: plasticity
      SCRIPTS: solid_plasticity_monolithic.py

plasticity_rankine:
   extends: .demo_template
   variables:
      DIRECTORY: plasticity_rankine
      SCRIPTS: rankine.py

spectral:
   extends: .demo_template
   variables:
      DIRECTORY: spectral
      SCRIPTS: |
         "solid_elasticity.py --formulation classic"
         "solid_elasticity.py --formulation spectral"

continuation:
   extends: .demo_template
   variables:
      DIRECTORY: continuation
      PARALLEL: False
      SCRIPTS: >
         continuation_planartruss.py
         continuation_planartruss_disp.py
         continuation_spatialtruss.py
         continuation_stardome.py
         continuation_schwedler.py

tdnns:
   extends: .demo_template
   variables:
      DIRECTORY: tdnns
      SCRIPTS: >
         solid_tdnns_2d_cantilever.py
         solid_tdnns_3d_cantilever.py
         solid_tdnns_3d_spanner.py
         solid_displ_3d_spanner.py
         solid_mixed_3d_spanner.py

units:
   extends: .demo_template
   variables:
      DIRECTORY: units
      SCRIPTS: >
         navier_stokes.py

beltrami:
   extends: .demo_template
   variables:
      DIRECTORY: beltrami
      SCRIPTS: solid_stressonly.py

obstacle:
   extends: .demo_template
   variables:
      DIRECTORY: obstacle
      SCRIPTS: >
         membrane.py
         montreal.py

structural_optimisation:
   extends: .demo_template
   variables:
      DIRECTORY: structural_optimisation
      PARALLEL: False
      SCRIPTS: truss_sizing.py

electrodiffusion:
   extends: .demo_template
   variables:
      DIRECTORY: electrodiffusion
      SCRIPTS: >
         pnp_4species_steadystate.py
         pnp_4species_transient.py
         pnp_4species_steadystate_scaled.py
         diffusor_4species_steadystate.py

book build:
   stage: book
   image: $CONTAINER_COMMIT_IMAGE-amd64
   script:
      - apt-get -y update
      - apt-get -y install nodejs npm
      - cd book
      - python bookstrap.py
      - jupyter book build --html
   after_script:
      - mv book/_build/html public
   artifacts:
      paths:
         - public
      expire_in: 2 hours
   rules:
      - if: ($CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH)
      - if: ($CI_PIPELINE_SOURCE == "merge_request_event" && 
            ($CI_MERGE_REQUEST_LABELS =~ /documentation/ || $CI_COMMIT_MESSAGE =~ /\[book\]/))
        variables:
            BASE_URL: "/mr-${CI_MERGE_REQUEST_IID}"

book release:
   stage: release
   script:
      - echo "Book accessible at ${CI_PAGES_URL}"
   pages:
      path_prefix: $PAGES_PREFIX
      expire_in: $PAGES_EXPIRE
   environment:
      name: "Book ${PAGES_PREFIX}"
      url: $CI_PAGES_URL
      auto_stop_in: 1 week
   rules:
      - if: ($CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH)
        variables:
           PAGES_PREFIX: ""
           PAGES_EXPIRE: never
      - if: ($CI_PIPELINE_SOURCE == "merge_request_event" && 
            ($CI_MERGE_REQUEST_LABELS =~ /documentation/ || $CI_COMMIT_MESSAGE =~ /\[book\]/))
        variables:
           PAGES_PREFIX: "mr-${CI_MERGE_REQUEST_IID}"
           PAGES_EXPIRE: 48 hours
